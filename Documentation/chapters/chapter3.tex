\chapter{Frankenbot: System Overview and Capabilities \label{cha:chapter3}}
In this chapter, you can find all the details about the implementation of a framework utilized to design the bot known as "Frankenbot". Additionally, there is a complete description of the system's architecture, features, and abilities of the framework. 
% Lastly, the chapter will be closed by highlighting future goals along with the conclusion.
\\~\\
If you are wondering where does the name "Frankenbot" comes from and why? So firstly, let me remove your confusion. It is derived from the fictional character known as "Frankenstein". It was first introduced in a novel written by Marry Shelley in 1818. Later on, after getting the hype it was promoted using different media sources like films, T.V. series, and also adopted by the gaming industry. Furthermore, the most well-known edition for its representation was the movie renowned by its original name released in 1931 \cite{frankenstein}. In this movie, Frankenstein was pictured as a haunted scientist who loved to dig the graves of humans and used to create new living beings by reassembling their expired body parts \cite{frankensteinmovie}. Likewise, Frankenbot is also a composition of different components as explained below in detail.

\section{Why Frankenbot?}
Currently, there are many states of the art dialogue frameworks available in the market like Rasa, Plato, and IBM Watson. But the question rises why Frankenbot and what makes it different from other well-known frameworks. There exist the following challenges that still need to be addressed.
\\~\\
Firstly, the question raises in mind that, is it possible to design a chatbot that is composed of several small chatbots? Secondly, what if the answer is yes? And one can build a giant chatbot using tiny virtual assistants then how can be the components and modules of a chatbot can be reused? Thirdly, how to make a platform-independent chatbot? In addition to that, another problem is the re-usability of a dialogue between different chatbots. Furthermore, there is another complication that can not be ignored is the rigidity handling for a chatbot. This proposes to inject the flexibility to a chatbot so that it can understand the dialogue consisting of multiple topics without displaying any alert message like "You are currently in the middle of the current dialogue. Are you sure to abort it?". Lastly, the biggest challenge is to design a chatbot that is capable of staying on the topic. This means it should be able to save the current dialogue state for each user instead of just responding with an answer that matches the user utterance irrespective of the current context in the conversation. 
\\~\\
For the above-mentioned challenges, there comes the Frankenbot to rescue and address them well. Additionally, the research completed under this master's thesis is an important step towards integrating different technologies. These technologies could include statistical dialogue managers, question answering, and slot-filler. The product implemented in this study provides the preparatory steps for it.

\section{Frankenbot: Experimental Chatbot}
The main idea behind the development of Frankenbot is to attest to the study of the modular framework implemented in this master's thesis. 
% An experimental chatbot named Frankenbot is designed to evaluate the research that happened under the shadow of this research. 
\subsection{Domain}
The demo chatbot has been designed using entertainment mechanism so that the participants do not lose interest during communication. For this purpose, a detective conversational agent was designed to solve a robbery case. The task assigned to Frankenbot was to ask the user different questions to come up with a decision whether a user answering to those questions is a culprit or not. Whereas, it has been expected from a user to answer the questions or talk generally about the corona virus and its stats, humor, gossips, and other related questions about bot's profile.

\subsection{Design}
Frankenbot has been designed to handle the answers for the questions thrown by it to the users. Secondly, it also has to respond efficiently in case of general conversation. To cope up with these challenging situations, it is provided with two modules. One module for detective dialogue and the other for general conversation. Both modules are implemented using a dialogue tree. Each dialogue tree is composed of interrelated child nodes. And all nodes collectively forming a tree are set to be responsible for containing all the relevant information about the specific module, intents available, and corresponding responses. 

\subsection{Training for NLU \label{sec:expchatbot}}
RASA NLU component has been adopted for the training of Frankenbot to understand the messages well. Additionally, it has been also used for detecting intent and entities in user utterances along with their respective confidence values.  It has been discussed thoroughly under Section \ref{subsec:rasanlu}.  
\\~\\
The detective model has been trained using 115 examples including 6 distinct intents ('\#affirm', '\#bye', '\#robbery\_time\_info', '\#purchasing', '\#greet', '\#negation'). Whereas, the general talk model has been trained by means of 205 statements including 9 distinct intents ('\#gossip', '\#psychology', '\#humor', '\#emotion', '\#coronaStats', '\#botFood', '\#general\_talk', '\#botProfile', '\#corona'). The json data provided for training can be found in Appendix \ref{appen:traindatastats}.

\subsection{Response Generation}
Lastly, the response is generated based on the detected intent with the highest confidence for a user utterance among all the available modules. Moreover, Frankenbot also checks for the current dialogue state and considers different parameters like the last active module and node for each user before responding. And for each intent, there exists a list of responses. And a response gets selected based on the mode assigned to it which can be either random or sequential.  

\section{Frankenbot as Concept}
This section highlights the theoretical functioning of the Frankenbot. Starting from the web-based interface designed for the users to provide input in the form of a text message. This input is passed to the chatbot by making simple get request using Web API. Once it is available to the chatbot for further processing then actual operation gets started.
\\~\\
Initially, the message is passed to a dialogue manager along with the session information and current dialogue state for a user. The dialogue manager holds the complete dialogue structure in the form of the dialogue trees. The number of dialogue trees represents the number of modules contained within a dialogue manager. Furthermore, each dialogue tree is composed of the tree nodes containing the modular information about the specific sub-state of a dialogue along with the intents and comparative responses.
\\~\\
Furthermore, a dialogue manager tries to find out the intent with the highest confidence value for the user utterance. For this purpose, all nodes of available dialogues trees are traversed. Each module contains a separate trained RASA NLU model and intent detection for response generation. A user utterance is processed through all of the generated NLU models to find out the intent and entities for input including the confidence values assigned to them. Later on, this information gets shared with a dialogue manager. It is responsible to keep a check for the highest activation value out of all the intents present in all modules. Additionally, it also keeps track of the module which includes the most confident intent. It also updates the node's activation information about the specific sub-state of a dialogue.
\\~\\
In the end, this information is delivered to a bot to generate a response based on the most confident intent and current state of dialogue for a user. Which is passed to the client as a response to an initial get request made using Web API by a user.
\\~\\
Session information for each user also gets stored along with the last active dialogue state for that specific user. Additionally, context variables are saved to make the response and dialogue more humanly.

\section{Frankenbot: Approach}
The Frankenbot is a chatbot composed of multiple chatbots. The design composes modules that work together to form a chatbot. General graphical representation is shown in Figure \ref{fig:frankOver}. 
\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{img/Frankenbot_Overview.PNG}
    \caption{Frankenbot Overview}
    \label{fig:frankOver}
\end{figure}

\noindent
As displayed, the example is composed of two modules: (i) "Dialogues Greetings and Small Talk" and (ii) "Question Answering System". And each module includes a dialogue tree demonstrating a complete dialogue structure for the respective module. So, "Dialogue Tree \#1" belongs to the greetings module, and "Dialogue Tree \#2" is linked with the Q\&A module. The module and dialogue tree has been explained in the section below.

\subsection{Module}
A module can provide the answer to a user's utterance. Therefore it requires an activation function Z that maps the current user utterance and the system state to a real number.
\begin{align*}
 Z: utterance, state \rightarrow R
\end{align*} 
For every user utterance, the dialogue manager calls all activation functions and chooses the model with the highest activation function. This module can then generate the answer. The module itself can be anything. It can be a classical intent-based system. Other systems are also possible. Some common examples of the modules are as follows:
\begin{itemize}
\item Bag of request/response pairs \cite{rrpairs}.
\item Waterfall Dialogue \cite{waterfallDial}.       
\item Slot-filler Dialogue \cite{slotfillerDial}.
\item Dialogue tree \cite{dialogTree}.
\item Question and Answering Dialogue \cite{q&aDialog}.
\item Knowledge Graph \cite{knowlGraph}.
\end{itemize}
\noindent
As a theory, a module can be more than a dialogue tree. Other systems (question answering, neural systems, etc.) can also fit in this framework, as long as they implement an activation function but it still needs to be tested. 
\\~\\
The classic slot-filler/single dialogue tree-based architecture is a basic possible module of the Frankenbot. Therefore the Frankenbot is at least as powerful as the slot-filler.

\subsubsection*{Traditional Dialogue Tree}
One of the data structures used to represent a dialogue is known as a dialogue or conversation tree. Usually, they consist of some sort of data stored in the hierarchical nodes. These nodes are also used to demonstrate the current state of the dialogue by pointing to the current node which has been processed lately. Furthermore, there exist to and fro relations between all the nodes. So this approach acts more likely as Simple Directed Graphs \footnote{\url{https://en.wikipedia.org/wiki/Directed\_graph}}. Just, for example, consider a dialogue with two dialogue sub-trees as shown in Figure \ref{fig:modArch}. In a traditional system we need to model:
\begin{itemize}
\item The transitions from the root node to the sub-tree.
\item The transitions inside each sub-tree.       
\item The transitions from each node to the root node(dashed lines: “I want to cancel this dialogue”).
\item To enable transitions between the sub-trees they would need to be modeled explicitly. In the example, this is omitted due to the complexity of the graph. Also, it is not possible to jump directly to the "subtree \#2" while being currently somewhere in "subtree \#1". Switching is only possible by following the available path to it.
\end{itemize} 

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.9\textwidth]{img/Modular_Architecture.PNG}
    \caption{Traditional dialogue tree containing two sub-trees.}
    \label{fig:modArch}
\end{figure}


\subsection{Modular Architecture}
There are various benefits for using modular architecture. 
% \subsubsection*{Modular Architecture's Characteristics}
Utilizing this architecture many features can be unlocked. Usability and performance can also be enhanced as mentioned below:

\paragraph*{Simpler but robust dialogue trees\label{par:simplerTree}}
The same dialogue as mentioned above but with the Frankenbot's framework modular architecture is shown in Figure \ref{fig:modArch2}. As you can notice the dialogue tree is less complicated and more powerful.
\begin{itemize}
\item Jump back to the root node is not necessary.
\item Switching between trees is possible without explicit modeling.       
\item Going back after switching is possible without explicit modeling.
\end{itemize}

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.9\textwidth]{img/Modular_Architecture_2.PNG}
    \caption{Dialogue with two sub-trees using Modular Architecture}
    \label{fig:modArch2}
\end{figure}

\paragraph*{Unification of Smaller Chatbots}
In this framework, all modules remain independent of each other. They are not tied together. Using this architecture the complexity of larger chatbots can be declined by dividing them into smaller liberated bots. In other words, the complexity of larger chatbots could be reached using the divide and conquer rule. This modular architecture provides a better framework for larger chatbots to grow. It also provides more customization options to a bot as one can easily add and remove any module from any bot at any time without caring for its dependencies.

\paragraph*{Modules Usability}
Modules can be reused within the same chatbot or different chatbots:

\begin{itemize}
\item \textbf{Usability within a Chatbot:} Modules can be reused within a chatbot. Just consider an example as shown in Figure \ref{fig:modReus2}. 
\\~\\
Imagine a chatbot from the smartphone support domain. Two dialogues require how to find out the model of the smartphone. The smartphone model will be stored as an environment variable. Transitions with a diamond tail are only possible when this environment variable is set. The transition with the dashed line does not leave the current node. It only activates the node in the next tree.
\begin{figure}[!h]
    \centering
    \includegraphics[width=0.9\textwidth]{img/Module_Reusability_2.PNG}
    \caption{Module usability within a chatbot}
    \label{fig:modReus2}
\end{figure} 
\\~\\
The same dialogue graph with a traditional dialogue tree is shown in Figure \ref{fig:modReus3} which has several restrictions and disadvantages. The module should be defined twice, more explicit relations needed to go back from one state to another and the dialogue trees are more complicated. Also the number of nodes and transitions will be higher as considered to Frankenbot's architecture resulting to higher processing as shown in the Table \ref{tab:tradVsFran}.
\begin{figure}[!h]
    \centering
    \includegraphics[width=0.9\textwidth]{img/Module_Reusability_3.PNG}
    \caption{Module usability within a chatbot}
    \label{fig:modReus3}
\end{figure}

\begin{table}[!h]
    \centering
   \begin{tabular}{ |c|c|c|c| } 
        \hline
         & \textbf{No. of Nodes} & \textbf{No. of Transitions} \\
        \hline
        \row{Traditional} & 21 & 26 \\ 
        \row{Frankenbot} & 15 & 14 \\ 
        \hline
    \end{tabular}
    \caption{Traditional vs. Frankenbot in terms of nodes and transitions.}
    \label{tab:tradVsFran}
\end{table}

\item \textbf{Usability among different Chatbots:} Usability can be enhanced by using modular architecture. Multiple chatbots can share common modules. The module needs to be defined only once. Changes in the module will automatically be integrated in all chatbots. Figure \ref{fig:modReus} shows visuals for better understanding of it. 
\begin{figure}[!h]
    \centering
    \includegraphics[width=0.9\textwidth]{img/Module_Reusability.PNG}
    \caption{Module usability between different chatbots}
    \label{fig:modReus}
\end{figure}       
\end{itemize} 

\paragraph*{Sense for Staying in the Topic}
The dialogue manager chooses the module with the highest activation function. But we can also add a term to stay in the topic: 
\begin{align*}
 Activation(module) = Z(utterance, state) + History(module)
\end{align*} 
Z is the activation function. History(module) is a term that gets bigger if the module has been active before. Therefore the module that was used before has a higher probability of being chosen which refers to the chatbot staying in the topic characteristic.

\section{Frankenbot: System Architecture}
Frankenbot’s system architecture has been sketched in Figure \ref{fig:sysArch}. It consists of a server and server-side web API. The user communicates using a browser and sends a request using web API to a server. Furthermore, the server contains the deployed Frankenbot's framework built using Python 3. Web server loads data for a chatbot from the JSON file for now but will be integrated with some database in the future. Whereas, a frontend for user's interaction has built simply using javascript, HTML, and CSS. Web API has been built using python library known as Flask \cite{flask}. 

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.9\textwidth]{img/System_Architecture_Updated.PNG}
    \caption{Frankenbot's System Architecture}
    \label{fig:sysArch}
\end{figure} 

\noindent
As it is clear from Figure \ref{fig:sysArch} that the communication between the client and the server is possible only via web API composed of a simple get request. In addition to that when you dig deep into the framework, it is composed of several different components.

\subsection{RASA Framework for NLU \label{subsec:rasanlu}}
RASA is an open-source renowned conversational artificial intelligence framework for designing contextual virtual agents. It is a machine learning framework designed to communicate through automated text and voice-based techniques. \cite{rasa}
\\~\\
For making it work, the following steps must be taken into account:
\begin{enumerate}
    \item Provide training data \cite{rasatrainingdata}.
    \item Provide configuration file with pipelines for training \cite{rasapipeline}.
    \item Provide directory's path to save trained models.
    \item Generate rasa interpreter by loading it from the trained models' directory.
\end{enumerate}
For utilizing it in a Frankenbot, necessary steps have been mentioned below under the heading of Configurations.
% \ref{par:config} in Frankenbot's Framework.
 
\subsubsection*{Training for RASA NLU}
It has been used for natural language understanding in Frankenbot. It needs to get trained first to produce some useful results and for that purpose, one needs to provide it with the training data. It can be provided using different formats as mentioned on its website \cite{rasatrainingdata}. For Frankenbot, JSON format has been adopted but it can be changed without any issue based upon the developer preferences. The format listed in Listing \ref{lst:rasaJson} consists of a top-level object called rasa\_nlu\_data, with the keys common\_examples, entity\_synonyms, and regex\_features. The most important one out of these all is common\_examples.

\begin{lstlisting}[language=json,firstnumber=1, caption=RASA NLU Training Data JSON Format., label={lst:rasaJson}]
{
    "rasa_nlu_data": {
        "common_examples": [],
        "regex_features" : [],
        "lookup_tables"  : [],
        "entity_synonyms": []
    }
}
\end{lstlisting}
\noindent
Moreover, common\_examples are a list of objects with the keys text, intent, and entities as shown in Listing \ref{lst:commonExampJson}. Whereas, entities can be an empty list or the objects list with the keys start, end, value, and entity.
 
 \begin{minipage}{\linewidth}
\begin{lstlisting}[language=json,firstnumber=1, caption=JSON Objects for common\_examples., label={lst:commonExampJson}]
{
    "text": "...",
    "intent": "#...",
    "entities": [
            {
                "start": ...,
                "end": ...,
                "value": "...",
                "entity": "@..."
            },
            ...
    ]
}
\end{lstlisting}
\end{minipage}

\subsection{Frankenbot Framework}
This framework is composed of various components. Each of which is responsible for performing a specific task. It has been majorly divided into the following two divisions: (i) The web server(backend), which is responsible for the creation of the whole chatbot and producing desired responses for a user and (ii) A client(frontend) also known as a user interface to interact with a chatbot. Both of these are explicitly explained below.
\\~\\
The detailed diagram for Frankenbot's Framework Architecture has been portrayed in Figure \ref{fig:frankArch}. All the components have been discussed in detail.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.9\textwidth]{img/Frankenbot_Architecture_Diagram_Updated.pdf}
    \caption{Frankenbot Framework Architecture Diagram}
    \label{fig:frankArch}
\end{figure} 

\subsubsection*{Client}
It is implemented using simple JavaScript, Html, and CSS. The template can be found under \cite{userinterface}. It is a simple user interface for a chat which allows a user to type a message and send it to the server by making simple get request utilizing the web API. 
\\~\\
Furthermore, it is also responsible for storing the user's session id to storage on a browser. For that purpose browser's "localStorage" \cite{localstorage} is used. If the user is connected to the first time to the server then it requests an empty session id and user utterance to the server. And as a response chatbot sends a welcome message and assigns an id to a user. Which is saved in the browsers local storage for every user. Whenever there comes a new request from this user to a server, the session id is being sent along with a user utterance to a server. In return, the server responds with a suitable response according to the user utterance which is being displayed next to the last user utterance. The response from the server is in the form of a JSON object which is being parsed to extract the chatbot's reply and displayed for a user. The important point to take into account is that the user id will be stored until the page is not reloaded or closed. If you want to restart your session and get away with all your previous chat, then you can simply refresh the web page and it will make a new instance of the chatbot. But for the future, a server will have the record of all dialogues that happened in a past stored in a database. 
\\~\\
For better understanding, the graphical representation of an interface is displayed in Figure \ref{fig:userInter}.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.9\textwidth]{img/User_Interface.PNG}
    \caption{Frankenbot's User Interface(Client)}
    \label{fig:userInter}
\end{figure}
\noindent
As demonstrated, the left side of the screen contains important information and instructions for a new user. Whilst, on its right, there exists a chat window showing the first most message as a welcome message for the newly arrived user. After that chat between the user and a bot initiated. The user can type a message in the bottom-most text box and press sends button or enter button from keyboard. The user's message will be displayed on the left side of the screen while the response will be shown on the right side of the screen's display and vice-versa according to your viewpoint.

\subsubsection*{Web Server}
The web server itself is a composite of multiple classes performing specific tasks and connected to a client using web API. It is written in Python version 3. Abstractly, it is responsible for performing all tasks required to make a chatbot functioning. Firstly it receives user utterance as a parameter and initializes a chatbot from data provided as a source file of the JSON format. After initializing a chatbot, it undergoes various actions for a user utterance to generate a response.

\paragraph*{Infrastructure Elements}

\subparagraph*{Web API}
It is implemented using the python library known as Flask. It is responsible for making a connection between the user and a server. It makes a user communicate with a server. Whenever there comes a new request from the client, firstly it passes from the function implemented for its handling.
\\~\\
Important tasks performed by the web API are:
\begin{enumerate}
    \item Receiving the user utterance and session id as a parameter from the get request made by the client.
    \item Checking whether the session id already exists or its a new user. If it happens to be a new user then there will be the empty user utterance and user session-id received as a parameter from the client's get request. It will initialize a chatbot using the data provided in the JSON file (discussed in detail below). Afterward, it assigns a new user session id and sends it along with a welcome message as a response to a client.
    \item If a session already exists, then it checks for the current dialogue state for an active user. And instead of initializing a new chatbot, the chatbot with the last stored state is being traversed with a new user utterance to get an appropriate response. And before responding to the client the current state gets updated again and stored for the current user.
     \item The response is being sent as a JSON object.
\end{enumerate} 

\subparagraph*{Persistence}
Persistence includes the Json Unseralizer. It takes the JSON file as an input and parses it for generating an initial chatbot.
\\~\\
The JSON file contains data as a JSON dictionary object which includes the name of a bot, welcome message, fallback message in case of no response, and a dialogue manager. Inside a dialogue manager, there exists a list of modules consisting of several modules having unique module ids. Additionally, each module contains a dialogue tree having a list of tree nodes. Whereas, each tree node includes a unique node id, information about its parent node, name of intent to which it belongs, and respective response generator. Furthermore, a response generator includes a mode for the responses that can be sequential or random and a list of responses. And all of the above-mentioned elements are uniquely identified using a key "type". For better understanding, just have a look at a JSON sample shown below in Listing \ref{lst:botJson}.
% caption=A first example

\begin{minipage}{\linewidth}
\begin{lstlisting}[language=JSON, firstnumber=1, caption=Frankenbot's JSON Structure., label={lst:botJson}]
{
  "type": "bot",
  "name": "...",
  "welcome_message": "Hi, ...",
  "fallback_message": "any desired message for bot's failure.",
  "dialog_manager": {
    "type": "max_activation_dialog_manager",
    "modules": [
        {
        "type": "dialog_tree",
        "module_id": "module1 or any id",
        "dialog_tree": [
          {
            "type": "tree_node",
            "node_id": any integer e.g 1,
            "parent_node": null for making root or any node id  to assign it a parent,
            "intent_name": "#...",
            "response_generator": {
              "type": "simple_response_generator",
              "mode": "sequential or random",
              "responses": [
                ...,
                ...
              ]
            }
          },
          ... ,
        ]
      },
      ... ,
    ]
  }
}
\end{lstlisting}
\end{minipage}
\\~\\
Theoretically, a bot is composed of a dialogue manager that contains information about all the modules representing the entire dialogue structure. Moreover, a module includes a dialogue tree that has been developed to design a dialogue. Each dialogue tree is made up of the relational tree nodes. And each tree node holds all the technical information about the intent and other required fields for a dialogue to produce the respected response.
\\~\\
Now coming towards practical implementation, a bot is generated recursively based on unique type key. The JSON data has been iterated and checks for the type of each element recurrently. And by taking that type of element into account, it returns the object for different respective classes. Let suppose the JSON object contains types in the following sequence:
\begin{enumerate}
    \item bot; recall the same function with a JSON for a dialogue manager returns a class Bot's object afterward.
    \item max-activation-dialogue-manager; recall the same function with a JSON for each module in a list of modules and returns a class MaxActivationDialogueTreeManager's object afterward.
    \item dialogue-tree; recall the same function with a JSON for a dialogue tree and returns a tree consisting of tree nodes afterward.
     \item tree-node; recall the same function with a JSON for each element of a list dialogue tree and returns a class Atom's object afterward.
     \item simple-response-generator; recall the same function with a JSON for a response generator and returns a class SimpleResponseGenerator's object afterward.
\end{enumerate} 
Now the function initiates and finds the very first type "bot" in a JSON data shown above. And then the recursive call to the same function is sent with "dialogue\_manager" JSON object. Likewise, sequential recursive calls happen for types "modules", dialog\_tree" and "response\_generator" with their specific JSON objects. Once it reaches the last key type "simple\_response\_generator" then it starts returning the corresponding class object related to each type as listed before. So, the function starts executing from the first step mentioned above but starts returning recursively from the last step. It means, the class SimpleResponseGenerator's object is passed as a parameter to the constructor of the upper-level class object i.e. class Atom in this case. The same goes for all other classes. In this way, class SimpleResponseGenerator's object gets appended to the class Atom's object, and so on. Finally, the class Bot object should contain the class MaxActivationDialogueManager's object as an attribute and that is how the chatbot will be generated recursively.
\\~\\
Also, there is a convention used to represent the intents, entities, and context variables. It has been taken from the state of the art chatbot IBM Watson as the intent is denoted by prefix "\#", an entity is denoted by "@" and "\$" symbol is used to denote a context variable. Same convention has been used in Frankenbot as shown in the Table \ref{tab:repIntEntCont}.

\begin{table}[!h]
    \centering
   \begin{tabular}{ |c|c|c|c| } 
        \hline
         & \textbf{Key} & \textbf{Value} \\
        \hline
        \row{Intent} & {\#intent\_name} & {intent\_value} \\ 
        \row{Entity} & {@entity\_name} & {entity\_value} \\
        \row{Context Variable} & {\$context\_var\_name} & {context\_var\_value} \\
        \hline
    \end{tabular}
    \caption{Representation for an Intent, Entity and Context Variable.}
    \label{tab:repIntEntCont}
\end{table}


\subparagraph*{Session}
It is responsible for session handling. It is subjected to establish "InMemorySession" which is meant to store session id in a list of session variables, context variables, and sequential response counter for each user. For each user, there exists a different chatbot's state. 
\\~\\
Whenever there comes a new user, the new dictionary object has been declared to store session id for a user along with its bot's state, active module id, and active node for each module. In addition to that, the last user utterance also gets stored for generating the last bot's message to the user if the chat window has been refreshed or reopened in a new tab of browser by a user(can be implemented in future). And then that dictionary object gets appended to a list of session variables. Which means there exists a separate object for each user in a list. It gets updated on every request from the client.
\\~\\
Another element present to save the context of dialogue for each user is known as context variables. They are independent of modules and get detected by NLU within a user utterance based upon the entities provided within the training data.  It is a dictionary having a user session id as a key, and each key represents a key-value pair for entities that appeared in a dialogue. Each entity name appeared in dialogue has been saved as \$EntitytName as a key and a value of the entity as its value. Its value gets updated every time if the same entity has been triggered or a new entity has been discovered in a dialogue for the same user. These context variables are used to understand the context of dialogue and update the entity value in a response if it is intended.
\\~\\
Another important attribute available is the response sequential counter. Its main task is to keep track of all intent's response counter for each user if its mode has been set to sequential. It means if an intent contains multiple responses and the bot has to produce a response for it based on the user utterance then each time the next response should be produced for a user. It is intended to give a more realistic impression to a user and human-like interaction behavior to a dialogue.

\subparagraph*{Configurations \label{par:config}}
To make chatbot work it is really important to provide it with proper configurations. Frankenbot needs three following directories to function:
\begin{enumerate}
    \item bot directory; It should be provided with the bot's directory name as a command-line parameter while running the project. For example, the running command in my case is "python app.py detective". In this command "detective" is the name of a directory which should contain JSON file for initializing a bot. And it should be named "frankenbot.json" (see Appendix \ref{appen:frankJson} to have a look at actual JSON data used for the structuring of the Frankenbot). 
    \item Furthermore, the bot directory must contain training data directory named as "rasa". Firstly, this sub-directory must contain a configuration file named as "config\_spacy.yaml" defining pipelines required for Rasa NLU Training\cite{rasapipeline} (see Appendix \ref{appen:rasaConf} to have a look on actual pipelines used). Secondly, JSON files must be available with training data for each module in "frankenbot.json". And the names for those training files should be the same as module id assigned to a module for which it contains training data. For example, "frankenbot.json" contains two modules, and ids assigned to them are detective\_tree and general\_tree. So, the training files should be named "detective\_tree.json" and "general\_tree.json" (see Appendix \ref{appen:traindatastats} to have a look at actual JSON training data used for both training of modules in the Frankenbot).
    \item Lastly, the model directory is required to store the rasa models produced after the model gets trained for each module. It can be any directory but one has to provide an appropriate path to it.
\end{enumerate} 

\paragraph*{Chatbot Elements}

\subparagraph*{Bot} Once the initial bot is generated, it is the very first element that has been instantiated. Originally it contains the complete definition for a chatbot. Which includes attributes such as chatbot's name, welcome message, fallback message, and most importantly dialogue tree manager(discussed below in next heading).
\\~\\
Whenever a request from a client has been made it firstly gets processed by this component. As it receives the user utterance, active tree nodes for each module for a particular user and session information as the parameters. 
\\~\\
Complete flow can be observed in Figure \ref{fig:flowBot}. The parameters are further passed to the dialogue tree manager to find a module with the highest intent's activation value, detected intent, intent's activation value, detected entities, entities activation values, active tree node, active module id, and JSON output object. This JSON object has been returned to a client containing all important information and respective response.
\\~\\
Before returning the response as a JSON object, it is also responsible for performing some major tasks. Firstly, it checks for detected entities received after the processing of its dialogue tree manager. If there exists any detected entity then entity(s) in the context variables for a particular user gets added or updated depending upon the current state of a bot.
\\~\\
In addition to that, it also checks for the detected intent's activation value for a user utterance. As Rasa's NLU has been used to detect the intent and there are the chances of getting a false result with very low activation value. So it checks for it and responds only if its value lies above some threshold. The range of activation value lies between 0 and 1. If the value is below the threshold then it checks for the last active node for a user whether it exists or not. If it doesn't exist then, it means the user started a chat with some meaningless utterance as an input for a bot. So, the chatbot should respond using node with intent anything\_else if it exists in a module with the highest activation obtained from RASA's NLU result. Secondly, if there exists some chatbot's active state for a user, then it checks for the last active module for a user and also checks for a node with an intent name anything\_else in its children. If it is available then the response has been generated using it. Otherwise, it simply responds with a fallback message.
\\~\\
Alternatively, if it is above the threshold then the highest module received from its dialogue tree manager has been used to generate an appropriate response(explained ahead).

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.9\textwidth]{img/bot_updated.pdf}
    \caption{Flow chart to finalize and update JSON output.}
    \label{fig:flowBot}
\end{figure}

\subparagraph*{Dialogue Manager} Dialogue manager is an abstract class whereas the max activation dialogue tree manager is an inherited class that should implement the abstract functions of a dialogue manager. Max activation dialogue manager originally contains the dialogue tree, once the chatbot has been initialized. Now the question arises what is the dialogue tree composed of? So, the dialogue tree gets generated while chatbot is loaded from the JSON file. And it is composed of the list of tree nodes, unique module id, data for RASA's NLU training and interpreter loaded from model directory once the training has been finished. Whereas, each tree node contains unique node id, information about its parent node,  intent, activation flag which gets set if it is responsible for generating a response, and a module object which itself consists of the intent detector and response generator. The dialogue tree has been generated using the python library "any tree" \cite{anytree}.
\\~\\
A detailed visual chart for a dialogue manager is portrayed below in Figure \ref{fig:flowDialogueMan}. It is responsible for finding a module with the highest activation based upon the detected intent's activation value for the user utterance. So for this purpose, each tree must be traversed for each of its nodes. As each node contains a module object which is further utilized for this purpose. Module's activation function is being called bypassing user utterance, RASA interpreter for the current module, module id for a recent module, and session data as parameters. And it returns activation value for each intent along with its name, recognized entities along with their activation values and the JSON object for output. As activation function for all nodes in each tree has been called and meanwhile dialogue manager keeps on checking for the activation value received for each node's module. And keeps on updating it whenever the last received value is greater than the previously stored value. In this way, the module with the highest activation is detected.
\\~\\
Responsibility of a dialogue manager not only ends here but it is also responsible to make the chatbot follow the modular architecture which is the main goal behind the designing of the Frankenbot. As explained above about the modular architecture that how should it work, let's discuss it here in a technical perspective. Whenever, the recently received activation value is greater than the last stored activation value and the identified intent is same as the current node's intent name then there comes following scenarios, if the recently traversed node is a root node or not: 
\begin{enumerate}
    \item If it is a root node then its activation flag should be set so that for the next time its children can be accessed for response generation. Also, all the required information must be stored and returned to the previously discussed bot component. Which is responsible for returning the response to the client via web API and the active state for the current user must get updated beforehand. 
    \item Secondly, if the recently processed node is not a root node then what should be its behavior? It is a bit complex strategy to follow. Firstly, it should check if its parent's activation flag is set or not. If it is set then it should proceed further otherwise it should not. Let's suppose that it is set and it steps ahead and finds multiple nodes with the same intent in its children nodes then it will not respond correctly. As it is the main idea behind the modular architecture that modules can be reused but different modules with the same intents do not need to have the same responses. Responses can differ at different levels in a tree whilst having the same intent. So for removing this problem, an active state for each module has been stored separately. This means if there exist two modules for a chatbot then there should be two separate active states, one for each module, available for a user. So by using these active states, it can match the last active node's id with the current node's parent id and if it is true then it is good to go. Also what if the user starts to enter the same user utterance again and again. It will again cause a problem as it will be searching for intent in the last active node's children but it will not be able to find it. So to overcome this issue, the manager matches the current node's id with the last active node's id and again if this condition has been satisfied then it should respond correctly. 
    \item Lastly, irrespective of the above conditions whether any of them is satisfied or not. It should return to a bot component which is meant to handle all scenarios and responsible to produce an appropriate response if there exists any highest detected module. Otherwise, it uses anything\_else node or fallback message to respond depending upon the state and design of the bot.
\end{enumerate} 
\noindent
In the end, it also checks for identified entities and their activation values and stores and updates them accordingly. And all the essential information is returned to a bot component. Which is responsible for returning the response to the client via web API and the active state for the current user should be updated beforehand.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.9\textwidth]{img/Dialogue_manager_updated.pdf}
    \caption{Flow chart to find module with highest activation value.}
    \label{fig:flowDialogueMan}
\end{figure}

\subparagraph*{Modules} Modules class is responsible for generating activation value for each intent which is passed to the dialogue manager for further processing as described above. In addition to that, it is also pledged for generating responses and JSON objects for API output. So these three functionalities should be implemented in a class inherited from abstract modules class. So, class Atom is inherited from it and provides all functional definitions for abstract class. 
\\~\\
There are two attributes needed for the atom class. One is natural language understanding(NLU) which is an object for rasa intent and entity detector and second is a simple response generator's object, Both of these components have been described next under their respective headings. 
\\~\\
Starting with an activation function is graphically represented in Figure \ref{fig:flowModule}. It initiates from a max activation dialogue manager's function to find a node's module with the highest activation value, all trees are traversed for each corresponding node. Each node contains a particular module object with its NLU and response generator. Using that module, activation function has been called provided user utterance, rasa interpreter, recent module id for a tree, and session information as parameters to it. And what it does with these parameters received is, it passes them further to make a call for natural language understanding to detect intents and entities. And the encountered intents and entities are then further passed for creating JSON object to return to the client as an API output. 

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.9\textwidth]{img/module.pdf}
    \caption{Flow chart for the module's activation function.}
    \label{fig:flowModule}
\end{figure}

\noindent
Moreover, it also has been used to generate a response with the help of the response generator for an encountered module with the highest activation based upon the identified intent and entities for a particular user.

\subparagraph*{Intent and Entity Detection}
It is one of the basic and necessary components for all chatbots. The same applies to Frankenbot. An intent and entity detector is responsible for the identification of intent and entities for a user utterance. So this feature must be handled within a successor class for it. So rasa intent entity detector is implementing this functionality for an abstract parent class.
\\~\\
Each tree node consists of an atom and each atom consists of the intent and entity detector with the intent and entities information stored for each node. Visuals for it have been displayed in Figure \ref{fig:flowIntandEnt} exhibiting a comprehended process. It is responsible to detect the intent and all the entities for the user utterance by utilizing the parametric RASA interpreter passed to it from the atomic activation function.
\\~\\
Coming towards internal processing, the user utterance is passed to the trained rasa interpreter to detect the intent and entities and matched with the current node's intent. If they have been appeared to be identical then the intent name is stored as a key in a dictionary object and a confidence value received from the result of the RASA interpreter represents its value. Also, the entities are stored as a list of dictionary objects and each object contains key-value pairs for entity name and confidence value, starting and ending index in an utterance. These detected intent and entities are returned from this function to its origin for further handling.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.9\textwidth]{img/Intent_entity_detector.pdf}
    \caption{Flow chart for the Rasa Intent and Entity Detector.}
    \label{fig:flowIntandEnt}
\end{figure}

\subparagraph*{Response Generation}
As the name itself is self-explanatory that what task should it perform. The response generator is liable for producing a response by taking an identified intent into the account. Additionally, it is also responsible for appending chatbot response to the final JSON object designed to be returned as an API output. 
\\~\\
The precedent classes must take in to account both of the functionalities that parent abstract class is responsible for. A simple response generator does it all for Frankenbot. As it needs mode for a response that can be sequential or random and a list of responses for a captured intent for response selection.
\\~\\
Once the pre-processing has been completed, means all the steps have been finished and the dialogue manager has returned the atomic module with the highest activation value and a chatbot needs to generate a response. Now, a bot uses that observed module to send a request to this component by providing it with recognized intents and entities along with session information as an input. So that it can go ahead and perform the task that it is responsible for. 
\\~\\
Its graphical representation is shown in Figure \ref{fig:flowRespGen} below. Firstly, it checks for the intent's sequential response counter for a specific user and updates it accordingly for next time usage. Secondly, after the selection of a response, it checks within a response for entities and context variables. If there is any detected entity for a user utterance and a response needs to be exchanged with its value then it should be handled here. Also, if there is any context variable stored previously for a user and bot's reply needs to get modified with its value then it should also be done here. After all, processing has been accomplished, it should create a JSON object with a chatbot response for web API output and send it back to a bot component for performing next required executions. 

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{img/Response_generator.pdf}
    \caption{Flow chart for response generation.}
    \label{fig:flowRespGen}
\end{figure}

\subparagraph*{JSON API Output}
After all components are done with their part, bot returns a JSON object to web API which passes it further to a client which is parsed at the client side for displaying needed information for a user. Let's start with an observation of JSON object demonstrated below in Listing \ref{lst:outputJson}.

\begin{minipage}{\linewidth}
\begin{lstlisting}[language=JSON, firstnumber=1, caption=Frankenbot's API JSON Output., label={lst:outputJson}]
{
    "user_utterance": {
        "text": "..."
    }, 
     "chatbot_utterance": {
        "type": "simple_response", 
        "response": "..."
    },
    "active_module": {
        "id": "...", 
        "type": "dialog_tree_module", 
        "activation_value": ..., 
        "module_output": {
            "recognized_intent": "...", 
            "recognized_entities": []
        }
    }, 
    "modules_output": [
        {
         "id": "...",
         "type": "dialog_tree_module",
         "activation_value": ... ,
         "module_output": {
            "recognized_intent": "...",
            "recognized_entities": [],
            "intent_ranking": [
               {
                  "name": "...",
                  "confidence": ...
               },
               ... ,
            ]
         }
      },
      ... ,
    ]
}
\end{lstlisting}
\end{minipage}
The JSON object contains user\_utterance which holds a key text for the user's message as a value. Secondly, chatbot\_utterance's response is a final reply by a chatbot. An active\_module reflects an id of the recognized module, activation\_value in terms of rasa's confidence value for an identified intent. Whereas, its child module\_output depicts an encountered intent and detected entities. Finally, modules\_output involves the dictionary object for all modules in a chatbot through which user utterance has been processed to generate a response after intent detection. So, id shows an id of a module, activation\_value is same just like as mentioned before for active\_module. Furthermore, module\_output is also similar to active\_module's module\_output but with an additional key for intent\_ranking. It is comprised of all the names for the intents and their respective confidence values obtained from rasa's trained natural language interpreter.

\subparagraph*{Logging}
It is something that has been used commonly nowadays to track the events occurring in any software or a system. 
\\~\\
For the framework, it has been implemented using python's library called "logging" \cite{logging}. Before returning the JSON object via web API to the client, this object with all the essential information from start i.e. received user utterance, till end i.e. generated suitable response, has been logged to a log file to keep track of the complete dialogue. Also, the log file contains the information for RASA's NLU training process and what intents and entities have been found in training data. Additionally, it also helps in tracking the error or reason of the chatbot failure, if any such event occurs.  


